

# logsitc baseline

- 编码
- 处理DAYS_EMPLOYED 365243
- fill median
- maxmin scaler

```
      fold     train     valid
0        0  0.731619  0.733108
1        1  0.734051  0.724274
2        2  0.732281  0.731479
3        3  0.731528  0.734834
4        4  0.732080  0.732027
5  overall  0.732312  0.731140
```
与之前做过 特征多项式的 baseline 相比 增加了异常值处理 和 scaler 性能提升了很多

0.671 -> 0.718  + 0.045


## lgb baseline

```
      fold     train     valid
0        0  0.817856  0.761383
1        1  0.834124  0.758432
2        2  0.822590  0.759136
3        3  0.814665  0.763950
4        4  0.816481  0.763113
5  overall  0.821143  0.761175
```
- 编码
- 处理DAYS_EMPLOYED 365243
- fill median
- maxmin scaler

train 比 valid 高 有点过拟合

[[Updated 0.792 LB] LightGBM with Simple Features
](https://www.kaggle.com/jsaguiar/updated-0-792-lb-lightgbm-with-simple-features/code)

LB 0.750 没有进行特征工程，没有结合其他table，模型已经到0.75了。。。。 真是模型的力量，或者是参数给定的好。。。
0.718  -> 0.075   + 0.032 


## 4 basic

### 01 fill_median minmax

```
      fold     train     valid
0        0  0.739638  0.732559
1        1  0.746269  0.723545
2        2  0.741525  0.730444
3        3  0.742379  0.732742
4        4  0.741852  0.731327
5  overall  0.742333  0.730025
```

fillna - median
scaler - minmax

只用四个特征就能达到 0.73 从何四个特征入手看看，不同的特征变换对模型提升的影响

### 01 fill_median minmax -> boxcox



```
      fold     train     valid
0        0  0.739591  0.732627
1        1  0.744069  0.723597
2        2  0.741525  0.730444
3        3  0.742400  0.732564
4        4  0.741854  0.731374
5  overall  0.741888  0.730045
```
有小幅提升 0.00002

LB  上根本显示不出来  0.721

## 4 amt

```
fold     train     valid
0        0  0.695288  0.640113
1        1  0.687265  0.649061
2        2  0.684464  0.644894
3        3  0.696154  0.642269
4        4  0.689214  0.647133
5  overall  0.690477  0.644576
```

```
      fold     train     valid
0        0  0.695173  0.640185
1        1  0.687569  0.649038
2        2  0.684670  0.645068
3        3  0.695650  0.642179
4        4  0.690054  0.646874
5  overall  0.690623  0.644564
```
还是  boxcox  居然没用  本来可以减小极端值的影响，
实际上 scaler 应该就基本解决了，看看有没有鸟用了


## amt 构造的 6 个新特征

```
      fold     train     valid
0        0  0.709908  0.688321
1        1  0.714082  0.678289
2        2  0.710798  0.682725
3        3  0.707469  0.679289
4        4  0.711917  0.682824
5  overall  0.710835  0.682212
```

```
      fold     train     valid
0        0  0.707708  0.688301
1        1  0.710322  0.678251
2        2  0.710798  0.682726
3        3  0.707470  0.679289
4        4  0.709478  0.682769
5  overall  0.709155  0.682196
```
![](https://ws3.sinaimg.cn/large/006tKfTcgy1fsrbifh2d1j30kk0q876m.jpg)


值得注意的是 amt_credit / amt_annuity
超过其他特征一倍
